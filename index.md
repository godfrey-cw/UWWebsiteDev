---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults
layout: home
---

I’m a machine learning researcher at [AKASA](https://akasa.com/), where I work
on end-to-end generative AI solutions for healthcare revenue cycle management.

Previously, I was an applied machine learning scientist at [Thomson Reuters
Labs](https://www.thomsonreuters.com/en/careers/our-jobs/join-thomson-reuters-labs.html),
tuning AI agents for knowledge workers, and a postdoctoral research associate at
[Pacific Northwest National Laboratory](https://www.pnnl.gov/) in Tegan
Emerson’s Math of Data Science group, mentored by [Henry
Kvinge](https://hkvinge.github.io/). Before that, I completed a PhD in
mathematics (algebraic geometry) at the [University of
Washington](https://math.washington.edu/), advised by [Sándor
Kovács](http://sites.math.washington.edu/~kovacs/current/index.html).

# Research

I work on applied research for LLM-driven machine learning systems. I am
interested in holistic evaluation of deep learning models, including bias,
robustness, explainability and interpretability, and post-hoc analysis of
learned features (e.g. representation (dis)similarity metrics).

My pure math research focused on birational geometry and singularities, mostly in
positive and mixed characteristic.

## Publications

*Note: my [Google Scholar](https://scholar.google.com/citations?user=yfT92d4AAAAJ&hl=en) profile may be more complete and up to date.

### Main Track

1. Davis Brown, Charles Godfrey, Nicholas Konz, Jonathan Tu and Henry Kvinge.
   [Understanding the Inner-workings of Language Models Through Representation
   Dissimilarity](https://aclanthology.org/2023.emnlp-main.403/).
   In *EMNLP 2023*.
1. Kelsey Lieberman, James Diffenderfer, Charles Godfrey and Bhavya Kailkhura.
    [Neural Image Compression: Generalization, Robustness, and Spectral
    Biases](https://arxiv.org/abs/2307.08657). In *NeurIPS 2023* (was
  also selected for an oral presentation at *ICML 2023 Workshop Neural
    Compression: From Information Theory to Applications*). Code available at
  [github.com/klieberman/ood_nic](https://github.com/klieberman/ood_nic)
1. Charles Godfrey, Davis Brown (equal contribution), Tegan Emerson and Henry
  Kvinge. [On the Symmetries of Deep Learning Models and their Internal
  Representations](https://papers.nips.cc/paper_files/paper/2022/hash/4df3510ad02a86d69dc32388d91606f8-Abstract-Conference.html).
  In *NeurIPS 2022*. Code available at
  [github.com/pnnl/modelsym](https://github.com/pnnl/modelsym).

### Workshop

1. Nicholas Konz, Charles Godfrey, Madelyn Shapiro, Jonathan Tu, Henry
    Kvinge and  Davis Brown. [Attributing Learned Concepts in Neural Networks to
    Training Data](https://arxiv.org/abs/2310.03149). In *The 1st Workshop on
    Attributing Model Behavior at Scale at NeurIPS 2023*, **selected for oral presentation**.
1. Charles Godfrey, Henry Kvinge, Elise Bishoff, Myles Mckay, Davis Brown, Tim
    Doster and Eleanor Byler. [How many dimensions are required to find an
    adversarial example?](https://arxiv.org/abs/2303.14173) In *The 3rd Workshop
    of Adversarial Machine Learning on Computer Vision at CVPR 2023*, **selected
    for oral presentation.**
1. Charles Godfrey, Michael Rawson, Henry Kvinge and Davis Brown. [Fast
   computation of permutation equivariant layers with the partition
   algebra](https://arxiv.org/abs/2303.06208). In *ICLR 2023 Workshop on Physics
   for Machine Learning*.
1. Davis Brown, Charles Godfrey (equal contribution), Cody Nizinski, Jonathan
   Tu, Henry Kvinge. [Robustness of edited neural
   networks](https://arxiv.org/abs/2303.00046). In *ICLR 2023 Workshop on
   Mathematical and Empirical Understanding of Foundation Models*.
1. Henry Kvinge, Davis Brown and Charles Godfrey. [Exploring the Representation
   Manifolds of Stable Diffusion Through the Lens of Intrinsic
   Dimension](https://arxiv.org/abs/2302.09301). In *ICLR 2023 Workshop on
   Mathematical and Empirical Understanding of Foundation Models*, [**featured
   in The
   Gradient**](https://thegradientpub.substack.com/p/challenges-for-personal-robotics?utm_source=profile&utm_medium=reader2).
1. Charles Godfrey, Elise Bishoff, Myles McKay and Eleanor Byler. [Impact of architecture on robustness and interpretability of multispectral deep neural networks](https://arxiv.org/abs/2309.12463). In *SPIE Defense + Commercial Sensing 2023*.
1. Elizabeth Coda, Nico Courts, Colby Wight, Loc Truong, WoongJo Choi, Charles
   Godfrey, Tegan Emerson, Keerti Kappagantula and Henry Kvinge. [Fiber bundle
   morphisms as a framework for modeling many-to-many
   maps](https://arxiv.org/abs/2203.08189). In *ICLR 2022 Workshop on
   Geometrical and Topological Representation Learning*.

## Preprints

1. Charles Godfrey, Ping Nie, Natalia Ostapuk, David Ken, Shang Gao and Souheil Inati. [Likert or Not: LLM Absolute Relevance Judgments on Fine-Grained Ordinal Scales](https://arxiv.org/abs/2505.19334) (2025).
1. [Correspondences in log Hodge cohomology](https://arxiv.org/abs/2301.00517) (2023).
1. Henry Kvinge, Grayson Jorgenson, Davis Brown, Charles Godfrey and Tegan
   Emerson. [Neural frames: A Tool for Studying the Tangent Bundles Underlying
   Image Datasets and How Deep Learning Models Process
   Them](https://arxiv.org/abs/2211.10558) (2022).
1. Charles Godfrey, Elise Bishoff, Myles Mckay, Davis Brown, Grayson Jorgenson,
   Henry Kvinge and Eleanor Byler. [Testing predictions of representation cost
theory with CNNs](https://arxiv.org/abs/2210.01257) (2022). Code available at
   [https://github.com/pnnl/frequency_sensitivity](https://github.com/pnnl/frequency_sensitivity).
1. Takumi Murayama and Charles Godfrey. [Pure subrings of Du Bois singularities
   are Du Bois singularities](https://arxiv.org/abs/2208.14429) (2022).
1. [Higher direct images of ideal sheaves](https://arxiv.org/abs/2207.01142) (2022).
